{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cred\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from langchain.tools import Tool\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.messages import HumanMessage, AIMessageChunk, SystemMessage\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\GEN_AI\\assist_ai_with_langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\dell nwc\\AppData\\Local\\Temp\\ipykernel_3052\\2316323586.py:67: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools,llm=llm ,agent=\"zero-shot-react-description\", verbose=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the function\n",
    "def get_train_details(train_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Query train information for a particular train number.\n",
    "    \n",
    "    Args:\n",
    "        train_number (str): The number of the train to get the status for.\n",
    "        \n",
    "    Returns:\n",
    "        str: train details for the train number.\n",
    "    \"\"\"\n",
    "    # Use a free railway api (replace with your API key)\n",
    "    api_key = cred.railway_token  # Replace with your API key\n",
    "    # enter current date in dd-mm-yyyy format\n",
    "    current_date = datetime.today().date().strftime(\"%d%m%Y\")\n",
    "\n",
    "    # complete_url variable to\n",
    "    # store complete url address\n",
    "    url = \"https://irctc1.p.rapidapi.com/api/v1/getTrainScheduleV2\"\n",
    "\n",
    "    querystring = {\"trainNo\":f\"{train_number}\"}\n",
    "\n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": \"a14450995dmsh0e8047dace38a23p1e2e4bjsnc01d4f66ed0c\",\n",
    "        \"x-rapidapi-host\": \"irctc1.p.rapidapi.com\"\n",
    "    }\n",
    "    result = requests.get(url,headers=headers,params=querystring)\n",
    "    if result.status_code == 200:\n",
    "        response=result.json() \n",
    "        train_name = response[\"data\"][\"train_name\"]\n",
    "        source_station = response[\"data\"][\"origin\"][\"station_name\"]\n",
    "        destination_station = response[\"data\"][\"destination\"][\"station_name\"]\n",
    "        \n",
    "        print(\" train name : \" + str(train_name)\n",
    "            + \"\\n source station : \" + str(source_station)\n",
    "            + \"\\n destination station : \"+ str(destination_station))\n",
    "        return f\"the train number {train_name} runs from station {source_station} to destinsation station {destination_station} .\"\n",
    "    else:\n",
    "        return f\"Failed to get data for {train_number}. Error: {result.json().get('message', 'Unknown error')}\"\n",
    "\n",
    "# Step 2: Wrap the function in a LangChain Tool\n",
    "train_detail_tool = Tool(\n",
    "    name=\"trainDetailsQuery\",\n",
    "    func=get_train_details,\n",
    "    description=\"Get the details of train for train number.\"\n",
    ")\n",
    "\n",
    "# Step 3: Test the tool\n",
    "# train_number = \"22222\"\n",
    "# result = weather_tool.func(train_number)\n",
    "# print(result)  # Prints the weather details for New York\n",
    "\n",
    "# Step 4: (Optional) Add the tool to an agent\n",
    "# from langchain.agents import initialize_agent\n",
    "# from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "# tools = [train_detail_tool]  # Add more tools if needed\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "# )\n",
    "# agent = initialize_agent(tools,llm=llm ,agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# # Use the agent\n",
    "# response = agent.run(\"What is the name of train 22222\")\n",
    "# print(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the function\n",
    "def get_train_status(train_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Query current status of a train for a particular train number.\n",
    "    \n",
    "    Args:\n",
    "        \n",
    "        train_number (str): The number of the train to get the status for.\n",
    "        \n",
    "    Returns:\n",
    "        str: train status for the train number.\n",
    "    \"\"\"\n",
    "    \n",
    "    current_date = datetime.today().date().strftime(\"%d%m%Y\")\n",
    "\n",
    "    # complete_url variable to\n",
    "    # store complete url address\n",
    "    url = \"https://irctc1.p.rapidapi.com/api/v1/liveTrainStatus\"\n",
    "\n",
    "    querystring = {\"trainNo\":\"22222\",\"startDay\":\"1\"}\n",
    "\n",
    "\n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": \"a14450995dmsh0e8047dace38a23p1e2e4bjsnc01d4f66ed0c\",\n",
    "        \"x-rapidapi-host\": \"irctc1.p.rapidapi.com\"\n",
    "    }\n",
    "    result = requests.get(url,headers=headers,params=querystring)\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "        task=\"text-generation\",\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "    )\n",
    "    if result.status_code == 200:\n",
    "        response=result.json() \n",
    "        chat_model = ChatHuggingFace(llm=llm)\n",
    "        messages = [SystemMessage(content=f'You are a great assistant which help me with the query related to train curret status, for your refference here is the data for the train {result.content}'),\n",
    "                    HumanMessage(content=\"give me the current status of train\")]\n",
    "        output=chat_model.invoke(messages)\n",
    "        \n",
    "        return output\n",
    "    else:\n",
    "        return f\"Failed to get data for {train_number}. Error: {result.json().get('message', 'Unknown error')}\"\n",
    "\n",
    "# Step 2: Wrap the function in a LangChain Tool\n",
    "train_status_tool = Tool(\n",
    "    name=\"trainStatusQuery\",\n",
    "    func=get_train_status,\n",
    "    description=\"Get the current status of train for train number.\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# #Step 3: Test the tool\n",
    "# train_number = \"22222\"\n",
    "# result = train_status_tool.func(train_number)\n",
    "# print(result)  # Prints the weather details for New York\n",
    "\n",
    "# # Step 4: (Optional) Add the tool to an agent\n",
    "# from langchain.agents import initialize_agent\n",
    "# from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "# tools = [train_detail_tool,train_status_tool]  # Add more tools if needed\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     do_sample=False,\n",
    "#     repetition_penalty=1.03,\n",
    "# )\n",
    "# agent = initialize_agent(tools,llm=llm ,agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "# # Use the agent\n",
    "# response = agent.run(\"What is the status of train 22222\")\n",
    "# print(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell nwc\\AppData\\Local\\Temp\\ipykernel_3052\\2718818631.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"
     ]
    }
   ],
   "source": [
    "# Step 4: (Optional) Add the tool to an agent\n",
    "tools = [train_detail_tool,train_status_tool,chat_model]  # Add more tools if needed\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "# agent = initialize_agent(tools,llm=llm ,agent=\"zero-shot-react-description\", verbose=True)\n",
    "# # Use the agent\n",
    "# response = agent.run(\"What is the status of train 22222\")\n",
    "# print(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools=[train_status_tool,train_detail_tool],  # Add multiple tools if needed\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,  # Ensures chat + tool usage\n",
    "    memory=memory,  # Enables remembering past messages\n",
    "    verbose=True  # Useful for debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Hello! How can I assist you today? If you have any questions or need information about a specific topic, feel free to let me know.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chatbot: Hello! How can I assist you today? If you have any questions or need information about a specific topic, feel free to let me know.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAI: Thought: Do I need to use a tool? No\n",
      "AI: Hello! How can I assist you today? If you have any questions or need information about a specific topic, feel free to let me know.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chatbot: Hello! How can I assist you today? If you have any questions or need information about a specific topic, feel free to let me know.\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")  # Take user input\n",
    "\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    response = agent.run(user_input)  # Pass user input to the agent\n",
    "    print(f\"Chatbot: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
