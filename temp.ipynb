{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command is using the pip package manager to install several Python packages: langchain, langchain_openai, langchain_community, langgraph, ipykernel, and python-dotenv. These packages are being installed in the current Python environment for use in the project or application.\n",
    "!pip install langchain langchain_openai langchain_community langgraph ipykernel python-dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_api_key=cred.hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv('huggingface_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\GEN_AI\\assist_ai_with_langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is a highly debated topic among football fans and experts alike. Whil\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "llm = HuggingFaceEndpoint(huggingfacehub_api_token=huggingface_api_key,model=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "question = \"Is Messi the best footballer of all time?\"\n",
    "output = llm.invoke(question)\n",
    "print(output[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.messages import HumanMessage, AIMessageChunk, SystemMessage\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "messages = [SystemMessage(content='You are a grumpy pirate.'),\n",
    "           HumanMessage(content=\"What's up?\")]\n",
    "output=chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arrr, th' sky be clear but me head be full o' grumps! What be ye askin' a grumpy pirate like meself? Ye best keep yer jestin' to a minimum if ye value yer petticoat, lass or lad!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell nwc\\AppData\\Local\\Temp\\ipykernel_6528\\436916316.py:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  output.dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': \"Arrr, th' sky be clear but me head be full o' grumps! What be ye askin' a grumpy pirate like meself? Ye best keep yer jestin' to a minimum if ye value yer petticoat, lass or lad!\",\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 57,\n",
       "   'prompt_tokens': 24,\n",
       "   'total_tokens': 81},\n",
       "  'model': '',\n",
       "  'finish_reason': 'stop'},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-fe4fc134-4559-4208-a60e-7b927d3bc443-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me about Song of Ice and Fire by GRRM.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "query_template = \"Tell me about {book_name} by {author}.\"\n",
    "prompt = PromptTemplate(input_variables=[\"book_name\", \"author\"], template=query_template)\n",
    "prompt.invoke({\"book_name\": \"Song of Ice and Fire\", \"author\": \"GRRM\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Deathly Hallows\" is the final book in J.K. Rowling's beloved \"Harry Potter\" series. Published in 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = HuggingFaceEndpoint(huggingfacehub_api_token=huggingface_api_key,model=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "# Create a chain\n",
    "chain = prompt | llm\n",
    "# Invoke the chain\n",
    "output = chain.invoke({\"book_name\": \"Deathly Hallows\", \"author\": \"J.K. Rowling\"})\n",
    "print(output[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "template = ChatPromptTemplate([\n",
    "   ('system', 'You are a helpful AI bot. Your specialty is {specialty}.'),\n",
    "   ('human', 'Explain the concept of {concept} based on your expertise.')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! In psychology, the concept of time is multifaceted and encompasses both how we perceive a\n",
      "-------------------------\n",
      "Certainly! While time is a fundamental concept in physics and philosophy, it also intersects with ec\n",
      "-------------------------\n",
      "Certainly! While my expertise primarily lies in politics, the concept of time is a fundamental aspec\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "specialties = [\"psychology\", \"economics\", \"politics\"]\n",
    "concept = \"time\"\n",
    "# Call the model with different personalities\n",
    "for s in specialties:\n",
    "   chain = template | chat_model\n",
    "   output = chain.invoke({\"specialty\": s, \"concept\": concept})\n",
    "   print(output.content[:100], end=\"\\n\" + \"-\" * 25 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq arxiv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published: 2019-08-28\n",
      "Title: Photosynthesis on Exoplanets and Exomoons from Reflected Light\n",
      "Authors: Manasvi Lingam, Abraham Loeb\n",
      "Summary: Photosynthesis offers a convenient means of sustaining biospheres. We\n",
      "quantify the constraints for photosynthes\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import ArxivQueryRun\n",
    "tool = ArxivQueryRun()\n",
    "print(tool.invoke('Photosynthesis')[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:27<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved at: generated_image.png\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain.tools import Tool\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "# Step 1: Load Stable Diffusion Pipeline\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"  # Stable Diffusion model on Hugging Face\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "#pipe = pipe.to(\"cuda\")  # Use GPU for better performance; switch to \"cpu\" if no GPU\n",
    "\n",
    "# Step 2: Define a custom tool for image generation\n",
    "def generate_image_via_api(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate an image using the Hugging Face Inference API.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Text description of the image to generate.\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the saved image file.\n",
    "    \"\"\"\n",
    "    response = requests.post(\"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\", headers={\"Authorization\": f\"Bearer {huggingface_api_key}\"}, json={\"inputs\": prompt})\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Save the image\n",
    "        file_name = \"generated_image.png\"\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return f\"Image saved at: {file_name}\"\n",
    "    else:\n",
    "        return f\"Failed to generate image: {response.json()}\"\n",
    "\n",
    "# Wrap it into a LangChain Tool\n",
    "image_generation_tool = Tool(\n",
    "    name=\"ImageGenerator\",\n",
    "    func=generate_image_via_api,\n",
    "    description=\"Generate images from text prompts using Stable Diffusion.\"\n",
    ")\n",
    "\n",
    "# Step 3: Add LangChain Tools (you can combine this with other tools)\n",
    "tools = load_tools([\"arxiv\"])  # Load LangChain's built-in tools\n",
    "tools.append(image_generation_tool)  # Add our custom image generation tool\n",
    "\n",
    "# Step 4: Use the tool in LangChain\n",
    "prompt = \"A futuristic cityscape at sunset, cyberpunk style\"\n",
    "result = image_generation_tool.func(prompt)\n",
    "print(result)  # This will print the path to the generated image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun  # pip install wikipedia\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import YouTubeSearchTool  # pip install youtube_search\n",
    "from langchain_community.tools.openai_dalle_image_generation import (\n",
    "   OpenAIDALLEImageGenerationTool\n",
    ")\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Möbius strip\n",
      "Summary: In mathematics, a Möbius strip, Möbius band, or Möbius loop is a surface that can be formed by attaching the ends of a strip of paper together with a half-twist. As a mathematical object, it was discovered by Johann Benedi\n"
     ]
    }
   ],
   "source": [
    "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
    "wikipedia = WikipediaQueryRun(description=\"A tool to explain things in text format. Use this tool if you think the user’s asked concept is best explained through text.\", api_wrapper=wiki_api_wrapper)\n",
    "print(wikipedia.invoke(\"Mobius strip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:26<00:00,  3.82s/it]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"  # Stable Diffusion model on Hugging Face\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "#pipe = pipe.to(\"cuda\")  # Use GPU for better performance; switch to \"cpu\" if no GPU\n",
    "\n",
    "# Step 2: Define a custom tool for image generation\n",
    "def generate_image_via_api(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate an image using the Hugging Face Inference API.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Text description of the image to generate.\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the saved image file.\n",
    "    \"\"\"\n",
    "    response = requests.post(\"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\", headers={\"Authorization\": f\"Bearer {huggingface_api_key}\"}, json={\"inputs\": prompt})\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Save the image\n",
    "        file_name = \"generated_image.png\"\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return f\"Image saved at: {file_name}\"\n",
    "    else:\n",
    "        return f\"Failed to generate image: {response.json()}\"\n",
    "\n",
    "# Wrap it into a LangChain Tool\n",
    "image_generation_tool = Tool(\n",
    "    name=\"ImageGenerator\",\n",
    "    func=generate_image_via_api,\n",
    "    description=\"Generate images from text prompts using Stable Diffusion.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=X1Vze17bhgk&pp=ygUVT2lsaW5nIGEgYmlrZSdzIGNoYWlu', 'https://www.youtube.com/shorts/pFMRevCZXvM']\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube = YouTubeSearchTool(\n",
    "   description=\"A tool to search YouTube videos. Use this tool if you think the user’s asked concept can be best explained by watching a video.\"\n",
    ")\n",
    "youtube.run(\"Oiling a bike's chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wikipedia, image_generation_tool, youtube]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "model_with_tools = chat_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text response: Hello! Not much, just here to help you out. How can I assist you today?\n",
      "Tools used in the response: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(\"What's up?!\")])\n",
    "print(f\"Text response: {response.content}\")\n",
    "print(f\"Tools used in the response: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text response: \n",
      "Tools used in the response: [{'name': 'ImageGenerator', 'args': {'__arg1': 'generate an image of a mountain bike'}, 'id': '0', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([\n",
    "   HumanMessage(\"Can you generate an image of a mountain bike?\")\n",
    "])\n",
    "print(f\"Text response: {response.content}\")\n",
    "print(f\"Tools used in the response: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "system_prompt = SystemMessage(\"You are a helpful bot named Chandler.\")\n",
    "agent = create_react_agent(chat_model, tools, state_modifier=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"What's up?\", additional_kwargs={}, response_metadata={}, id='1fe99b20-d73e-4607-b6f9-e815195555f1'),\n",
      " AIMessage(content='Hello! Not much, just here to help you out. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=35, prompt_tokens=382, total_tokens=417), 'model': '', 'finish_reason': 'stop'}, id='run-31738121-a062-4b74-90d4-e94da2520177-0')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "response = agent.invoke({\"messages\": HumanMessage(\"What's up?\")})\n",
    "pprint(response[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke({\"messages\": [\n",
    "   HumanMessage('Explain how photosynthesis works.')\n",
    "]})\n",
    "print(len(response['messages']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage: Explain how photosynthesis works.\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: Photosynthesis\n",
      "Summary: Photosynthesis ( FOH-tə-SINTH-ə-sis) is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into the chemical \n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: Photosynthesis\n",
      "Summary: Photosynthesis ( FOH-tə-SINTH-ə-sis) is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into the chemical \n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: Photosynthesis\n",
      "Summary: Photosynthesis ( FOH-tə-SINTH-ə-sis) is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into the chemical \n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: Photosynthesis\n",
      "Summary: Photosynthesis ( FOH-tə-SINTH-ə-sis) is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into the chemical \n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: Photosynthesis\n",
      "Summary: Photosynthesis ( FOH-tə-SINTH-ə-sis) is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into the chemical \n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: Photosynthesis\n",
      "Summary: Photosynthesis ( FOH-tə-SINTH-ə-sis) is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into the chemical \n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: Photosynthesis\n",
      "Summary: Photosynthesis ( FOH-tə-SINTH-ə-sis) is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into the chemical \n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: Photosynthesis\n",
      "Summary: Photosynthesis ( FOH-tə-SINTH-ə-sis) is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into the chemical \n",
      "--------------------\n",
      "AIMessage: Photosynthesis is a system of biological processes by which photosynthetic organisms, such as most plants, algae, and cyanobacteria, convert light energy, typically from sunlight, into chemical energy stored in molecules like glucose. This process primarily takes place in the chloroplasts of plant cells, where chlorophyll captures the light energy. During photosynthesis, carbon dioxide (CO2) and water (H2O) are converted into glucose and oxygen (O2). The overall chemical equation for photosynthesis is 6CO2 + 6H2O + light energy → C6H12O6 + 6O2.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for message in response['messages']:\n",
    "   print(\n",
    "       f\"{message.__class__.__name__}: {message.content}\"\n",
    "   )  # Print message class name and its content\n",
    "   print(\"-\" * 20, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(agent, query):\n",
    "   response = agent.invoke({'messages': [HumanMessage(query)]})\n",
    "  \n",
    "   for message in response['messages']:\n",
    "       print(\n",
    "           f\"{message.__class__.__name__}: {message.content}\"\n",
    "       )  # Print message class name and its content\n",
    "      \n",
    "       print(\"-\" * 20, end=\"\\n\")\n",
    "  \n",
    "   return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessage(\n",
    "   \"\"\"\n",
    "   You are a helpful bot named Chandler. Your task is to explain topics\n",
    "   asked by the user via three mediums: text, image or video.\n",
    "  \n",
    "   If the asked topic is best explained in text format, use the Wikipedia tool.\n",
    "   If the topic is best explained by showing a picture of it, generate an image\n",
    "   of the topic using Dall-E image generator and print the image URL.\n",
    "   Finally, if video is the best medium to explain the topic, conduct a YouTube search on it\n",
    "   and return found video links.\n",
    "   \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage: Explain the Fourier Series visually.\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Image saved at: generated_image.png\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: ['https://www.youtube.com/watch?v=spUNpyF58BY&t=477s&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D', 'https://www.youtube.com/watch?v=ds0cmAV-Yek&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D']\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: ['https://www.youtube.com/watch?v=spUNpyF58BY&t=477s&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D', 'https://www.youtube.com/watch?v=DY8AAsRrFUM&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D']\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: ['https://www.youtube.com/watch?v=spUNpyF58BY&t=477s&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D', 'https://www.youtube.com/watch?v=ds0cmAV-Yek&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D']\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: ['https://www.youtube.com/watch?v=spUNpyF58BY&t=477s&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D', 'https://www.youtube.com/watch?v=DY8AAsRrFUM&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D']\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: ['https://www.youtube.com/watch?v=DY8AAsRrFUM&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D', 'https://www.youtube.com/watch?v=spUNpyF58BY&t=477s&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D']\n",
      "--------------------\n",
      "AIMessage: Here are the video links to visually explain the Fourier Series:\\n1. https://www.youtube.com/watch?v=DY8AAsRrFUM&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D \\\\- This video provides a clear analysis of the Fourier Series.\\\\\\n2. https://www.youtube.com/watch?v=spUNpyF58BY&t=477s&pp=ygUcRm91cmllciBTZXJpZXMgdmlzdWFsaXphdGlvbg%3D%3D \\\\- This video offers an illustrative explanation with visual aids.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(chat_model, tools, state_modifier=system_prompt)\n",
    "response = execute(agent, query='Explain the Fourier Series visually.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanMessage: What did I ask you in the previous query?\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: How to Train Your Dragon (novel series)\n",
      "Summary: How to Train Your Dragon is a series of children's books written by British author Cressida Cowell. The books are set in a fictional Fantasy Viking world, and focus on the experiences of protagon\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: How to Train Your Dragon (novel series)\n",
      "Summary: How to Train Your Dragon is a series of children's books written by British author Cressida Cowell. The books are set in a fictional Fantasy Viking world, and focus on the experiences of protagon\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: How to Train Your Dragon (novel series)\n",
      "Summary: How to Train Your Dragon is a series of children's books written by British author Cressida Cowell. The books are set in a fictional Fantasy Viking world, and focus on the experiences of protagon\n",
      "--------------------\n",
      "AIMessage: \n",
      "--------------------\n",
      "ToolMessage: Page: How to Train Your Dragon (novel series)\n",
      "Summary: How to Train Your Dragon is a series of children's books written by British author Cressida Cowell. The books are set in a fictional Fantasy Viking world, and focus on the experiences of protagon\n",
      "--------------------\n",
      "AIMessage: It seems like you are providing a summary from the Wikipedia entry for 'How to Train Your Dragon (novel series)'. Since you've given a detailed text summary, I don't need to call another function to provide more text information. How can I assist you further with this series or any other topic?\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "response = execute(agent, query=\"What did I ask you in the previous query?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver.from_conn_string(':agent_history:')\n",
    "agent = create_react_agent(chat_model, tools, checkpointer=memory, state_modifier=system_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
